--------------------------------------------------
PROJECT STATUS SUMMARY (2026-02-01)
--------------------------------------------------

GOAL
Build a Cloudflare-first Next.js app to learn vocabulary from film/series subtitles.
Core flow: upload subtitle -> parse -> store vocab -> learn -> track progress.

MY PLAN (NEXT IMPLEMENTATIONS)
1) Quality controls
   - Add a reprocess/retranslate tool per episode/pack to refresh meanings.
   - Add better meaning QA (optional validation model or secondary source) and deeper admin review workflow.

2) Admin tools
   - Improve subtitle library: search, filters, pagination.
   - Add bulk actions (delete pack, reprocess pack, export vocab).

3) Learning experience
   - Improve vocab list UX (sorting, filters by POS/status).
   - Add spaced repetition / review queue and progress charts.
   - Show per-word repetition counts across the full film.
   - Add sorting by repeat frequency (high→low / low→high).

4) Reliability & ops
   - Add background job metrics and processing logs.
   - Improve cache/usage monitoring for Google Translate.

WHAT IS IMPLEMENTED (HISTORY OF IMPLEMENTATION)
1) Upload + Processing
   - Admin uploads subtitles at /subtitles (R2 storage).
   - Processing runs inline when queue is absent; queue handler supported when configured.
   - Subtitle parsing extracts sentences and terms.
   - POS tagging + lemma extraction with wink-nlp (lazy-loaded).
   - Occurrences stored in D1 (vocab_occurrences + vocab_terms + subtitle_files).

2) Vocabulary + Learning Pages (D1-backed)
   - /dashboard: shows content + progress stats.
   - /film/[filmId]: shows episodes for a contentId from D1.
   - /[contentId]/[episodeId]: shows vocab list with meanings + computed status badges.
   - /episode/[episodeId]: legacy episode vocab view.
   - Word rows show surface form + lemma.
   - Word rows show repetition counts across the film.
   - POS dropdown and repeat-frequency sorting are available.
   - Word list sorted by lemma.
   - Report flow is moved to quiz: users can report after answering with a suggested correction.

3) Authentication + Roles
   - Username/password auth (no email).
   - First registered user becomes ADMIN.
   - Admin-only: /subtitles, /processing, /usage, and upload API.
   - Sessions stored in D1; cookie-based session token.

4) Progress Tracking
   - word_status table: per-user weak status per word (set on wrong answers).
   - user_lemma_status table: learned status per lemma.
   - Status is computed: weak > learned (lemma) > new.
   - Dashboard progress counts learned lemmas per user.

5) Translation (Bangla meaning)
   - Google Translate API v2 (API key).
   - Meanings cached in translation_cache + vocabulary.
   - Monthly usage tracking in D1 (translation_usage).
   - Limit controlled by GOOGLE_TRANSLATE_MONTHLY_CHAR_LIMIT (default 500,000).
   - Meanings are generated on-demand via admin action (not during upload).
   - Admin stats show total terms, known/missing meanings, estimated chars and cost.

6) Admin Tools
   - /subtitles includes upload + list + delete pack action.
   - /subtitles shows meaning stats per pack and manual “Process meanings” button.
   - Admin can edit lemma/pos/meaning per word.
   - Admin can mark word OK or delete word.
   - Admin can filter reported words and apply user suggestions.
   - /usage shows current month Google Translate usage + limit (UTC).

7) Data Model Extensions
   - Store surface term + lemma per occurrence.
   - Support meaning overrides per occurrence.
   - Track corruption flags for vocab and overrides.
   - Track quiz stats per user/episode/term.
   - Track user reports + suggested corrections (vocab_reports).

DEPLOYMENT & CONFIG
- Build command for CI: npm run build
- Deploy command: npm run deploy
- Custom domain: learn.ataullah.dev -> worker "vocab"

REQUIRED CLOUD RESOURCES
- D1: vocab-db (binding: VOCAB_DB)
- R2: vocab-subtitles (binding: SUBTITLE_BUCKET)
- Optional Queue: vocab-subtitles-queue (binding: SUBTITLE_QUEUE)

MIGRATIONS
- 0002_vocab_schema.sql (base schema)
- 0003_seed.sql (demo data; optional)
- 0004_word_status.sql (status table + pos column)
- 0005_translation_usage.sql (usage tracking)
- 0006_auth.sql (users + sessions)
- 0007_surface_terms.sql (surface term + lemma storage)
- 0008_corruption_flags.sql (corrupt flags)
- 0009_quiz_and_lemma_status.sql (lemma status + quiz stats)
- 0010_google_translate_provider.sql (usage provider merge)
- 0011_vocab_reports.sql (quiz report storage)

RUNNING LOCAL
- npm run migrate:local
- npm run dev:cf (uses Wrangler preview + .dev.vars)

LOCAL ENV (.dev.vars)
NEXTJS_ENV=development
GOOGLE_TRANSLATE_API_KEY=...
GOOGLE_TRANSLATE_PROJECT_ID=...
GOOGLE_TRANSLATE_MONTHLY_CHAR_LIMIT=500000
GOOGLE_TRANSLATE_COST_PER_MILLION=20

NOTES
- Meanings are generated on demand; use the admin “Process meanings” action per pack.
- Meanings are processed in batches so big packs require multiple passes (handled automatically).
- Reported words are hidden from normal users; admins review via "Reported only" filter.
- Quiz supports any question count; 0 means "use all available".
- MCQ practice sets learned on correct answer and weak on wrong answer.
- Dark mode supported with user toggle + system preference.

--------------------------------------------------
